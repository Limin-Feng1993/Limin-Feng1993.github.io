---
layout:     post                  
title:     开放式大气学科因果推理型知识图谱的构建（一）
subtitle:  An Open-Ended  Knowledge-Graph (KG) of Causal Reasoning in the Atmospheric Science
date:       2019-10-23
author:     Limin                    
header-img: img/Fox.jpg    
catalog: true                     
tags:                             
    - 博士研究
---

> 注：该系列文章为博士期间笔者的研究记录。本文是对未来研究的构想，可以看作是开题报告，共计约一万字，读完约30分钟。为防止意外的发生中断研究，本系列文章所使用的代码与数据集均在Github上公开发布，以便该研究的可持续性和可重复性。


# 0.引言

&nbsp; 该研究的缘起，是笔者在最近几年的研究发现，自己获得实验数据相对来说较容易，但是理解这些数据的内涵和意义却能困扰我好几个月的时间。周围的研究者也抱有同感，甚至这不是大气科学一个学科的问题，而是自然科学普遍存在的问题。当我发现科研过程中最痛苦、最耗时的过程其实是发现研究结果在整个学科脉络中的意义，并将其用通俗易懂的语言表达给听众或者读者时，我决定停止“造车轮”式的重复性研究，下定决心拔掉脚下这个困扰我已久的肉中刺，以便继续向前走路。

&nbsp; 连我这个初出茅庐的底层科研人员都发现的问题，国家最高决策层方面自然也会注意到。2019年1月，国家自然科学基金委发布年度[基金申请指南](http://www.nsfc.gov.cn/nsfc/cen/xmzn/2019xmzn/01/04dq/001.html)，其中在地球科学部分提到：**……特别注重时空大数据的地学解释服务，地球科学既注重理解过去，更关注服务现在和预测未来。**  在计算机科学蓬勃发展的助力之下，地球科学的研究也产生了大量的数据。每个科研院所、高校、公司的服务器上都囤积了大量的存储量论TB算的硬盘。但是，应该与之相匹配的数据解释却仍然是薄弱环节。我们花费海量的时间成本和金钱成本获得的数据，却得不到真正有用和急需的科学结论。跟人一样，吃了很多东西难消化，虽说瘦不了，但是肠胃也很难受。

&nbsp; 明朝文学家张岱说“天下学问，唯夜航船中最难对付。” 一个人在海上，没有信号，身边没有书，也没有参谋，这个时候确实发现卖弄知识是一件很累的事。但是，我认为这个时候显示出来的学问纯属“掉书袋”，一个行走的书柜而已（我承认这段话也是掉书袋）。真正活的知识，并不在对着天涯过客喝大酒时体现出来。让知识永葆活力的唯一办法是让它牢牢嵌入到原有的知识网络中，与其他节点相连、融合、拓展和应用。 一切阅读、学习，最终都要归结到这张网络里面。知识是为实践服务的，博观而约取。从聚焦问题开始，拉扯出一张知识网络去学习、专研、应用，才是"知行合一"。
 
&nbsp; 科学研究是一项长期的、连续的脑力和体力运动，它的根本目标是把知识编织成一张相互关联的网络，在这个过程中加入了各式注脚和同行审议。对于科学来说，独立事实的价值微乎其微，哪怕它在自己的世界中能讲得通，例如伪科学和超科学，就像是没有和已有知识网络相连的孤立节点。至于宗教，它和科学的区别在于后者能承认自己的某些网络节点是错的。如果能通过一个特殊的方法将所有知识有结构地组织起来，那么就会对人类知识的范围和界限有更清晰地视野。在未来几十年里，以人工智能为驱动的计算机会将全部文献编织成一个单一的知识网络，这个网络会培育出新形式的权威。

&nbsp; 很难想象还有其他的事务会像人工智能那样拥有改变一切、摧枯拉朽的力量。在某个现有进程中植入极少量有效的人工智能都会将其效率提高到全新水平。比如把人工智能加入语言中，用它在堆积如山的文本中寻找证据，识别法律案件中的矛盾，或是优化科学论据的使用。在技术发展日新月异的今天，“一万小时成就资深专家定律”基本上会被束之楼阁，工作往往会要求他们在24小时或更短的时间内，迅速了解一个完全陌生的领域，并且拿出专业的解决方案。所有人都会成为菜鸟且永远都能会是菜鸟，这与年龄、经验、职业都没关系。人工智能可以帮助我们这些菜鸟从浩如烟海的信息库中探寻出规律和答案。但是即使人工智能改变了全球经济以及文明，它也会像所有的基础设施一样让人感到极度无聊。把人类从重复性、机械性、记忆性的工作中解放出来，到此人工智能的历史使命就算完成，人类还有额外的艰巨任务：用独有的智慧、丰富的情感以及艺术美感，去解读、创作、表达更好的知识，证明自己存在的价值。

&nbsp; 我觉得和其他领域的朝气蓬勃的年轻人一起登上“第四次工业革命”的战车，是一件非常幸运和荣耀的事情，哪怕要做出巨大的牺牲。“道阻且长，行则将至”。任何伟大的事业都有一个微不足道的荒谬开头，让我们开始吧。

# 1. 研究背景 

## 1.1 大气模型的符号推理逻辑

> All models are wrong, but some are useful.by George Box

&nbsp; 自文艺复兴后，自然科学和孕育它的人文科学分道扬镳，越来越倾向于形式逻辑，而人文科学越来越倾向于辩证逻辑。大气科学是地球科学的分支，而地球科学又是自然科学与人文科学交叉重叠的领域。大气科学的主干由几百年以来逐步演化推进的数学物理方程和化学反应式构成，然而大气科学的根基却是对自然现象的不断探索，与人类生存息息相关。没有洪涝、暴雨、闪电、台风、沙尘、雾霾、海潮，也就没有对大气的探测过程和物理建模过程，大气科学就会停留在牛顿经典力学的层面。大气科学的迷人之处和恼人之处是相同的，它的复杂性使得“三段论”的形式逻辑无数次被证明失败，也使得“矛盾能统一”的辩证逻辑无数次因盘根错节而体系崩溃。

&nbsp; 科学理论的构建通常使用数学演绎和归纳法。形式逻辑“三段论”的基本组成部分是前提、规则、结论。演绎的目的是求出结论，使用规则和前提来推导出结论，数学家通常使用这种推理。归纳的目的是求出规则，借由大量的前提和结论所组成的实例，来学习规则，自然科学家通常使用这种推理。欧几里德是第一个以三段论形式的演绎法用于构建实际知识体系（几何学）的人。此后，演绎推理成为西方近代科学发展的重要形式，并由此诞生了牛顿力学。麦克斯韦在1865年用演绎法推导出电磁波存在，并预言了光是电磁波，尽管当时没有实验数据证明。然而罗吉尔·培根认为演绎法不能作为科学应用的思想方法，“思而不学则殆”，而只有归纳法才是真正的科学的思想方法，并且把对实验结果的归纳和数学演绎推理看成是探求知识的两条不同的道路。归纳推理也是历史学家发现统计规律时普遍采用的方法，其局限性是容易困在历史数据中，难以外推至未来。且由于归纳法高度依赖观测数据，由于仪器方法的改进、测量位置和方式等变化，数据本身存在不同程度的误差。

&nbsp; 在大气科学领域，演绎推理的巅峰是大气流体力学方程组，归纳推理的经典案例是南极臭氧层空洞的发现。此外还有溯因推理，溯因目的是求出前提，借由结论和规则，来支援前提以解释结论，医疗诊断和侦探破案通常使用这种推理。《论语》记载“子入太庙，每事问”。无论什么棘手的问题，只需要连续不断地问为什么就能得到真相。同一个结果往往由多种原因引起，因而人们在应用溯因推理时，常常需要同时推测多种原因。在大气科学中的应用例如推导全球变暖的成因。造成上个世纪开始的全球变暖趋势原因，既有可能是太阳黑子活动异常，或者冰川期循环，或者地球本身周期性公转轨迹变动，也有可能是水汽、二氧化碳、甲烷等温室气体排放量增加所致。尽管如此，这些推理仍然不能很好的解释2000年以后的变暖趋势停顿。

&nbsp; 大气的流动是粘性流体运动。1822年，纳维建立了粘性流体的基本运动方程；1845年，斯托克斯又以更合理的基础导出了这个方程，这组方程就是沿用至今的Navier-Stokes方程(简称N-S方程)。N-S方程和质量守恒和连续方程、地球自转科氏效应、热力学第一定律、理想气体方程构成了大气动力学的理论基础, 但是这组偏微分方程是无法求解的。尽管如此，科学家们的理论推理决对不会停止，逐渐通过演绎推理的方式得到更多的数学公式，也逐渐通过各种仪器的观测结果，经归纳推理加入了更多的经验公式，例如计算饱和水汽压的经验公式，是对无法求解的Clausius–Clapeyron偏微分方程的近似。1971年超级计算机问世后，开始对全部方程组求出相对精确的数值特解<sup>[1]</sup>。

[1] Bauer P, Thorpe A, Brunet G. The quiet revolution of numerical weather prediction[J]. Nature, 2015, 525: 47.

&nbsp; 大气流体方程组求解的思路是如何把连续流体在计算机上离散化成一个个的网格。大气模型网格的大小从几公里到几百公里。由于计算机性能的限制，网格不能设置的过小。实际的大气流动往往异常复杂(例如湍流)，理论分析和数值计算会遇到巨大的数学和计算方面的困难。有很多物理过程的发生范围远小于一个网格的大小，这些过程只能用经验性的参数方案来近似，例如云微物理方案<sup>[2]</sup>。即使是它们在数值求解上可能是有效的，并且可以解释，但是过于简化了。例如云雾滴由于颗粒物的内核或者气泡的存在，不满足N-S方程中连续的不可压缩流体假设。所以云雾物理永远是大气科学家挥之不去的梦魇。不仅仅是微尺度，大尺度环流如造成寒潮的冷涡等也难以模拟和预测。

[2] Andreae M O, Rosenfeld D. Aerosol-cloud-precipitation interactions. Part 1. The nature and sources of cloud-active aerosols[J]. Earth-Science Reviews, 2008, 89: 13-41.

&nbsp; 大气的预测性是有限的。即使是用超级计算机，全球天气数值模型GCPMs的预测结果在6天之后准确性开始出现明显下降，17天之后，预测准确率降至为气候平均态，亦即与猜成过去几年的平均值一样的误差<sup>[3]</sup>。即使是一个很小的扰动或者计算误差，也会对全球大气模式带来较大影响。1963年，气象学家洛伦兹提出了在确定性系统中的非周期现象。模式中参数的微小改变将导致完全不一样的结果，使有规律的、周期性的行为，变成完全混乱的状态，称之为“混沌理论”。大气中存在无序的运动，例如布朗运动。这种运动具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中与之前的历史无关。这种最初只在气象中出现的混沌无序现象，后来被发现存在于众多的自然和社会系统中，诸如精神病的发病、心率的节奏、股市的波动等。虽然一个确定的非线性系统可能产生随机结果，但更关键的是发现随机性后面的有序性。

[3] Judt F. Insights into Atmospheric Predictability through Global Convection-Permitting Model Simulations[J], 2018, 75(5): 1477-1497.

&nbsp; 类似于地球科学的形式推理，在20世纪70年代，计算机科学家开始在地质学、医疗等领域打造专家系统，亦即由大量的专家手动编制一系列规则，然后由符号推理形式，根据前提推导出最后结果。这条路后来很快难以为继。因为机器是单纯的接受方，不能主动做改变自己逻辑的事情，所有的事情必须由人类专家一条一条的以规则化的方式去做，非常僵硬（学术界大部分培养人才方式也是如此）。这是人工智能中的符号学派，诞生于人工智能的早期，它的失败基本上确定了形式逻辑存在外推极限。自然科学的形式主义逻辑推理已经走过漫长岁月，未来发展方向是如何将其运用到计算机的思考模式。因为即使有一天原子世界的逻辑都覆灭了，牛顿力学、相对论、量子力学都不成立了，但是比特空间的逻辑也不会失效，信息熵公式（S=-p*log p）将永存。

> 如果有四件事各有25%的发生几率，我们知道这个时候用00，01，10，11各表示一个事件就可以完全表示出这个随机事件。由信息熵公式可得2bit，也就是说这个事件的信息量是2bit。和自然科学的定律不同，这个定律独立于原子空间而存在。

## 1.2 人工智能的概率统计逻辑

> If you torture the data long enough, it will confess anything. by Ronald Coase

&nbsp; 如果说地球科学的形式推理就像是在下围棋，精打细算，一步一步的能推导得出下一步的确定结果，那么现实世界就像是德州扑克，存在不确定性，每一件事的发生都有概率。甚至由于人的参与和观测实验，事物的原先状态发生改变，背离了发展轨道，“见相非相”。从统计学角度，所有的现实问题都可转换成概率问题。因此，去寻找现实世界问题的解决方案就等价于寻找一个概率分布。这就是人工智能的概率统计逻辑。

&nbsp; 人工智能有三大流派：符号主义，又称逻辑主义、心理学派或计算机学派，是通过分析人类智能的功能，然后通过计算机来实现这些功能。符号主义有两个基本假设：（1）信息可以用符号来表示；（2）符号可以通过显式的规则（比如逻辑运算）来操作。人类的认知过程可以看作是符号操作过程。在人工智能的推理期和知识期，符号主义的方法比较盛行，并取得了大量的成果。连接主义，又称仿生学派或生理学派，是认知科学领域中的一类信息处理的方法和理论。在认知科学领域，人类的认知过程可以看做是一种信息处理过程。连接主义认为人类的认知过程是由大量简单神经元构成的神经网络中的信息处理过程，而不是符号运算。因此，连接主义模型的主要结构是由大量的简单的信息处理单元组成的互联网络，具有非线性、分布式、并行化、局部性计算以及自适应性等特性。符号主义方法的一个优点是可解释性，而这也正是连接主义方法的弊端。深度学习的主要模型神经网络就是一种连接主义模型。行为主义主要从生物进化的角度考虑，主张从和外界环境的互动中获取智能。随着深度学习的发展，越来越多的研究者开始关注如何融合符号主义和连接主义，建立一种高效并且具有可解释性的模型。

&nbsp; 20 世纪70 年代，研究者意识到知识对于人工智能系统的重要性。特别是对于一些复杂的任务，需要专家来构建知识库。1965年，美国斯坦福大学费根鲍姆领导他的研究小组开始研制化学专家系统DENDRAL，并于1968年研制成功。这是世界上第一个专家系统。1976年，费根鲍姆又领导他的研制小组研制成功了用于细菌感染患者的诊断和治疗的医学专家系统MYCIN，为专家系统的研究与开发提供了范例和经验。1981年，斯坦福大学国际人工智能中心的杜达（R．D．Duda）等人研制成功了地质勘探专家系统PROSPECTOR，为专家系统的实际应用提供了最成功的典范。

&nbsp; 专家系统是使用人类专家推理规则的计算机模型，用来处理现实世界中需要专家作出解释的复杂问题，并得出与专家相同的结论。专家系统一般采用知识表示和知识推理等技术来完成通常由领域专家才能解决的复杂问题，因此专家系统也被称为基于知识的系统。专家系统可视作知识库和推理机的结合。知识库是专家的知识在计算机中的映射，推理机是推理逻辑在计算机中的映射。知识库是对物质及概念作实体的分析，并确认彼此之间的关系，可以看作存储了关于世界的事实。推理机将逻辑规则应用到知识库中，推导出新知识。这个过程将迭代，因为知识库中的每个新事实可以触发推理引擎中的附加规则。

&nbsp; 建立专家系统的一般步骤是先设计初始知识库，概括知识表示所需要的关键概念及其关系，如数据类型、已知条件(状态)和目标(状态)、提出的假设以及控制策略等。然后编制规则，把形式化了的知识变换为由编程语言表示的可供计算机执行的语句和程序。确认规则后，检验知识的合理性、规则的有效性。专家系统已经在各个领域得到了广泛地应用并收到良好的效果，但它们解决问题的范围常常受到限制。目前，传统专家系统缺陷主要表现为以下几个方面：

- 知识推理是专家系统的核心，专家系统的系统功能很大程度上取决于系统已拥有的知识，但不具备自学习能力，其知识获取主要由知识工程师来完成，这是一件十分困难和费时的事情。
- 大部分的专家系统都是针对某一特定领域建立的，一旦越出这一特定领域，系统就有可能无法再有效地运行。
- 缺乏知识的重用性和共享性，与主流信息技术脱节，不具备并行分布和多专家协同功能。只能在单个处理机上运行，不具备功能分解后分布到多个处理机上去并行工作的能力。而并行分布是现代信息系统的一个重要特征。不能实现相近领域或同一领域不同方面的多个分专家系统的协作问题求解。而协作求解也是现代信息系统的一个重要特征。这基本上是一种信息孤岛，与主流信息技术，如Web技术、数据库技术等脱节，这就严重影响了其发展和应用。
- 处理不确定问题的能力较差，在归纳推理、模糊推理、非完备推理等方面的能力较差。

&nbsp; 未来专家系统的发展方向是新型的模糊专家系统、神经网络专家系统、分布式专家系统、协同式专家系统和基于Web的专家系统等。 在新型专家系统中，除演绎推理之外，还应有归纳推理，各种非标准逻辑推理，以及各种基于不完全知识和模糊知识的推理等等。同时适合在多处理器的硬件环境中工作，在总体上提高系统的处理效率。能综合若干个相近领域的或一个领域的多个方面的子专家系统互相协作共同解决一个更广领域问题。着第三波人工智能高潮发展之前移动互联网的发展，网络已成为用户的交互接口，软件也逐步走向网络化。专家系统的发展也顺应该趋势，将人机交互定位在网络层次。

&nbsp; 然而对于人类的很多智能行为（比如语言理解、图像理解等），我们很难知道其中的原理，也无法描述出这些智能行为背后的“知识”。因此，我们也很难通过知识和推理的方式来实现这些行为的智能系统。为解决这类问题，研究者开始将研究重点转向让计算机从数据中自己学习。一个容易理解的例子是让机器具有飞行能力不需要模拟鸟的飞行方式，而是应该研究空气动力学。

&nbsp; 传统的特征学习技术过于依赖人工及相关的专业知识，困难且昂贵。深度神经网络虽然可以有效地学到数据丰富的特征，但特征难以解读。通常神经网络层数越多，训练成本也越高。但是单纯从统计方法出发，可能会产生另外一些问题，因为统计模型一般都是基于具体问题设计的参数化模型，我们仍然需要去手工建模，而这些建模工作就是一个非常耗费精力的过程。深度学习表面上是不用提取数据特征了，但实际还是需要根据结果情况不断地修改网络结构，这其实就是把以前的特征工程后置了而已。

&nbsp; 云沿着时空方向的演化规律会满足一定的守恒律及连续性限制，发现物理问题的特殊性并寻找对应的表征量也是解决问题的关键。根据流体力学中的泰勒冻结假设(Taylor Frozen Hypothesis)，认为流场中存在显著的时空关联特性。泰勒假设虽然一直没有得到严格的证明，而且此假设中实际还隐含着平稳气流和均匀湍流的条件，风速也不宜过小，但根据实际观测资料的验证，泰勒假设在大气边界层中是适用的。其认为雷达反射图中的云团在短时间内趋向于在空间以当地平均对流速度平移，短时间内并不会发生外形或者反射强度的剧烈改变。

&nbsp; 关于目前流行的深度学习方法：

&nbsp;目前的挑战：一是优化目标的定义；二是可用数据，你能否拿到足够多的可用数据；三是模型的可解释性，如何处理对模型结果推理过程的置疑。模型因果性、可解释性：相关性建模涉及的两个因素未必有直接的因果关系，得出的这个模型，如何解释它最后结果的意义，这一点就横亘在很多模型最后产品化、产业化的路上面。在工业界，广义线性模型(generalized linear models)还是占据了大壁江山，这要归功于其良好的解释能力。特定领域的知识帮助我们更好的解释机器学习模型的结果，得到需求受众的认可，这才是算法落了地。

&nbsp; 深度学习逻辑框架的底层缺陷：本质是基于概率统计。随机性是统计模型的灵魂。虽然在建立模型时，我们希望统计模型能准确地抓住自变量与因变量之间的关系，但是当因变量能够100%被自变量决定时，这时候反而没有统计模型什么事了。深度学习寻找那些重复出现的模式，因此重复多了就被认为是规律（真理），因此谎言重复一千遍就被认为真理，所以为什么大数据有时会做出非常荒唐的结果。

&nbsp; “臭名昭著”的深度学习黑箱，来自于大量非结构数据输入之后，算法进行归纳的逻辑无从掌握。必须具有可解释性。图网络可以操作知识的归纳逻辑，看出行为的因果关系，显然对是黑箱性的一次突破。

&nbsp; 深度学习的另一个问题，就是很多算法必须经历超大规模训练来提升精度。而这也是对算力和数据的暴力消耗。如果能让AI具备逻辑上的迁移可能，那么具备人类常识的AI，将可以在很小的数据样本中完成相对复杂的工作。

&nbsp; 人工智能的地基是统计学。但是和统计学不同，人脑神经系统是一个由生物神经元组成的高度复杂网络，是一个并行的非线性信息处理系统。人脑神经系统可以将声音、视觉等信号经过多层的编码，从最原始的低层特征不断加工、抽象，最终得到原始信号的语义表示。人类大脑是经过了上亿年的进化才形成了如此复杂的结构，但至今仍然没有完全了解。我们并不理解大脑的运作原理，以及如何产生意识、情感、记忆等功能。人类智慧的源泉在哪？是知识、经验、推理能力，这是人类理性的根本。统计方法本身通常无法找到“有意义”的、经得住推理考验的规律，它只能找到重复出现的模式，亦即“三人成虎”、“谎言重复一千遍就被当成了真理”。人工智能系统非常脆弱容易受攻击或者欺骗，需要大量的数据和计算资源，而且计算过程如同“黑箱”，结果不可解释。人工智能的未来是“知识表示与推理”、“不确定性处理”、“人机交互”。了解实际应用场景，牢记以结果为导向的解决问题的思维方式，将现有的语言和领域知识整合到模型中，使人和机器相得益彰，实现人工智能和人类智能的双向结合，这才是“盛德大业”——让所有人都能得益才能长久。

## 1.3 知识网络的连接反馈逻辑

> I saw the best minds of my generation destroyed by statistical models. by Jeff Hammerbacher

&nbsp; 我们的数学直觉很差，人类的大脑更不擅长统计，数学和概率统计都并不是我们天生的思考方式。人脑的智慧体现在德州扑克式的不确定性推理和模糊性决策，外加行为主义的反馈逻辑。人是怎么认识这个世界的呢？

## 1.4 知识网络与统计模型、物理模型混合逻辑

&nbsp;数值模式背后有坚实的数学物理方程组做依托，但是计算复杂性过高，迭代求解成本大，同时受限于资料同化，准确的源清单等。《Deep Distributed Fusion Network for Air Quality Prediction》文章模型主要是应用了深度学习，首先对大量不同类别的特征做embedding，然后分别组合输入到不同的子网络再进行融合。子网络是为了捕捉不同影响因子的作用，如气象要素，其他污染物要素，时空要素等。 

&nbsp;《Tackling Climate Change with Machine Learning》指出现在的气候预测大多还是基于气候模式，计算代价巨大。机器学习的引入势必将突破目前数值模式巨大的计算瓶颈。目前机器学习在气候预测上的应用大多还是在模式后处理阶段，用于进行多个气候预测模式结果的融合，而直接融合机器学习算法的气候预测模型目前还没有成熟落地的方案。该领域应用的大多数的ML模型还都是黑箱，对于未来的改进，有待于结合domain knowledge和模型本身提高模型的可解释性。对于ML和AI的应用探索，更需要结合更多的domain knowledge，构建可解释性更强的模型，去更好的服务我们的需求。

&nbsp; 混合模型方法，将物理过程模式与数据驱动型机器学习的通用性耦合起来。现代科学论述包括假设检验、理论发展和计算机建模，这些都是以统计和物理关系，即相关定律为基础的。地球系统数据在激增，信息收集速度远大于人们所能消化的速度。数据的增多并未带对系统预测能力的提高，科学家需要对数据进行理解。 一些时空动态特征比如“记忆效应”可以作为feature手动加入到传统机器学习中，但最新的深度学习已经没有这些限制。但是地学中没有类似被标记的大量训练样本。物理建模（理论驱动）与机器学习建模（数据驱动）过去往往被认为是两个领域，具有不同范式。但其实两种方法可以相互补充的，前者外推能力强，后者更灵活可发现新规律。深度学习将逐渐取代一些半经验的物理模型，未来只会保留最少的基本物理模型，同时指出深度学习在地球科学的应用的最大挑战是理解数据其中的意义。

Reichstein, M., Camps-Valls, G., Stevens, B., Jung, M., Denzler, J., Carvalhais, N., and Prabhat, 2019, Deep  learning and process understanding for data-driven Earth system science: Nature, v. 566, no. 7743, p.  195-204. 

&nbsp; 预测气候的困难主要来自于气候的响应是非线性的。将全球气候模式预报的结果赋予统计学的意义，检测潜在的关联，在经典假设检验的基础上决定是对是错，是存是留(41741 个关系)。

Caldwell, P. M., Bretherton, C. S., Zelinka, M. D., Klein, S. A., Santer, B. D., and Sanderson, B. M., 2014, Statistical  significance of climate sensitivity predictors obtained by data mining, v. 41, no. 5, p. 1803-1808.

&nbsp; 数值模式代表了几百年以来自然科学积累和技术进步的产物，但是细数起来并很少有根本的物理规律上的突破。云雾降水、边界层过程等次网格过程的理解不全面，才需要参数化。1950年，Thompson等人首次量化初始误差对于后续预测结果的影响， 劳伦兹在量化大气系统的可预测性过程中提出了混沌理论。它的主要结论是不稳定系统具有确定的、静止的可预测性，导致了模型不确定性的量化成为模型的必需。混沌系统的非线性变化意味着纯统计模型是无法量化预测的不确定性的。物理模型本身的固有缺陷需要一个完全不同的方法来解决。

Bauer, P., Thorpe, A., and Brunet, G., 2015, The quiet revolution of numerical weather prediction: Nature, v.  525, p. 47.

&nbsp; 贝叶斯方法是一个非参数化的统计概率方法，利用它可以实现自动化分析数据，结果可解释，无论数据是大是小。数据越大，预测能力越高。它将变革机器学习和科学模型。许多大数据就是小数据的集合。Automatic Statistician (http://www.automaticstatistician.com)。

Ghahramani, Z., 2015, Probabilistic machine learning and artificial intelligence: Nature, v. 521, p. 452.

&nbsp; 非监督学习一直以来被监督学习的成功光芒所掩盖。然而，长期来看，非监督学习更加重要。人类和动物的学习方式是非监督性的。深度学习方法属于表示学习，人工智能的最终发展趋势是将表示学习和复杂推理结合在一起。新的方法需要取代基于特定规则的符号表示，例如向量化和分布式表示。

LeCun, Y., Bengio, Y., and Hinton, G., 2015, Deep learning: Nature, v. 521, p. 436.

&nbsp; 深度学习是可以应用到自然界复杂的物理过程中的。背景先验知识可以用来设计深度学习框架。数值模式和深度学习二者可以互补。

de Bezenac, E., Pajot, A. & Gallinari, 2017, Deep learning for physical processes: incorporating prior scientifc  knowledge.


# 2. 方法论

&nbsp; 严格来说知识表示和知识推理是密切相关的两个概念，但实际上知识表示也经常用来直接指代包含推理的广义概念，因此合并为知识表示与推理。

&nbsp; 知识图谱就是对客观世界的描述。它描述实体的属性关系，每一个实体可能有若干个属性，实体和实体之间有很多关系，每一个关系基本上可以理解为是一个事实。多元异构知识图谱的构建涉及到在开放的、海量的数据里怎么样去挖掘数据、构建超大规模知识图谱。互联网上海量的多形态数据，蕴含了很多行业应用的有价值信息。从大量无标签非结构化数据中进行开放知识挖掘，抽取了大量的 SPO 三元组。百度飞桨PaddleNLP通过语义空间变换技术实现实体消歧、实体归一等等，解决知识表示形式多样，关联融合困难的问题。百度构建了一个非常庞大的知识图谱，里面含有 6 亿中文实体，事实的量或者说各种关系量已经达到了 3780 亿，比我们人类大脑里面储备的知识多得多。某种程度上，互联网可以被理解为客观世界的一个映射。另外一个映射是在封闭的各行业的领域知识里。ERNIE2.0 通过基于多任务学习的预训练任务迭代，不断提升模型性能。通过对百科、对话，篇章结构、网页搜索、语义关系等超过 13 亿知识不断地学习，不断地积累，ERNIE 在多项中英文自然语言处理任务上取得了业界最好效果，目前已在Github上开源。语言生成，包括机器辅助写作和智能自动创作。创作中可能需要更多辅助的素材，把很多相关的内容呈现出来，这个时候需要做信息的推荐，加入一些领域知识库，一些历史相关的事件脉络，帮助写作。当然还有标题和摘要的生成，这个需要归纳总结，也是很有技术含量的。保证质量包括文本纠错、低质检测、词语润色添加文章标题、自动摘要、文本分类。

&nbsp; 目前的自然语言处理还没有很好地解决常识和推理的问题。新的 NLP 范式是使用大规模文本语料库进行预训练，然后使用特定任务的小数据集进行微调。DNN-NLP 极大地依赖于算力和标记数据，并且也在建模、推理和可解释性方面面临巨大挑战。AI 芯片的新军备竞赛使 AI 研究非常昂贵。

&nbsp; 知识表示（KR）就是易于计算机处理的方式来描述大脑的知识。知识 = 精炼后的数据。好的KR是同时为机器和⼈设计的。例如：ConceptNet (http://conceptnet.io/): json格式, API调用将词语向量化。 RDF： Triple-based Assertion model, Resource Description Framework (资源描述框架)：最简单、最接近自然语言和人脑认知的数据模型。An RDF triple （S,P,O） encodes a statement—a simple logical expression, or claim about the world. RDF是最值得重视的知识图谱表示框架。

&nbsp; 知识图谱工程指的是从不同来源、不同结构的数据中进行知识提取，形成知识存入到知识图谱。文本一般不作为知识图谱构建的初始来源，而多用来做知识图谱补全。KG Embedding/知识图谱嵌⼊ = Entity Vector & Relation Vectors/实体向量和关系向量 =Distributed Representations/知识图谱的分布式表示。关系预测与关系推理是基于知识图谱做挖掘和分析主要任务。

&nbsp; 和机器学习解决问题的思路一样，**本研究计划也属于工程问题**。工程问题进展的关键，是考虑约束条件下清晰地定义了目标函数和损失函数 (Loss Function)。所以只要做两件事：一是把目标定量化，二是建立起评测系统，此后不管工程的进展快慢，都能慢慢进化到最优。

## 2.1 目标函数

- 动机“善”：让天下没有难写的文章。
- 解释“真”：基于经典知识网络建构，不断验真。
- 展现“美”：数据可视化与绘图制片大众传播。
- 合乎“道”：前瞻领域+技术门槛高+市场一片蓝海。

## 2.2 损失函数

## 2.3 应用场景

&nbsp; 并行计算资源成本的削减。

1.数据分析得出定量结论—机器学习流水线
2.知识网络链接赋予意义—拓扑图谱流水线
3.总结概括主旨表达清晰—自然语言流水线

# 3. 尾声

&nbsp; 生命之树常青，而理论是灰色的。人们每天看到的、遇到的只是一个表象，怎样从自然和社会的表象中发现其内在的规律，通过对这些表象的整理和分析就会得出一些更本质的东西，再经过人的思维取舍抽象，这就是科学和思想。研究是看别人看到的，想别人想不到的。历史和数据都是一样的，不一样的是怎样取舍、整合、解读、用一根什么样的线把它们穿起来。学术上的独创有时候仅仅是总结出一个概念而已。

**谁终将声震人间，必长久深自缄默；谁终将点燃闪电，必长久如云漂泊。**


