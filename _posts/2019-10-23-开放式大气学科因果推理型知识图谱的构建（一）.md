---
layout:     post                  
title:     开放式大气学科因果推理型知识图谱的构建（一）
subtitle:  An Open-Ended  Knowledge-Graph (KG) of Causal Reasoning in the Atmospheric Science
date:       2019-10-23
author:     Limin                    
header-img: img/Fox.jpg    
catalog: true                     
tags:                             
    - 博士研究
---

> 注：该系列文章为博士期间笔者的研究记录。本文是对未来研究的构想，可以看作是开题报告，共计约一万字，读完约30分钟。为防止意外的发生中断研究，本系列文章所使用的代码与数据集均在Github上公开发布，以便该研究的可持续性和可重复性。


# 0.引言

&nbsp; 该研究的缘起，是笔者在最近几年的研究发现，自己获得实验数据相对来说较容易，但是理解这些数据的内涵和意义却能困扰我好几个月的时间。周围的研究者也抱有同感，甚至这不是大气科学一个学科的问题，而是自然科学普遍存在的问题。当我发现科研过程中最痛苦、最耗时的过程其实是发现研究结果在整个学科脉络中的意义，并将其用通俗易懂的语言表达给听众或者读者时，我决定停止“造车轮”式的重复性研究，下定决心拔掉脚下这个困扰我已久的肉中刺，以便继续向前走路。

&nbsp; 连我这个初出茅庐的底层科研人员都发现的问题，国家最高决策层方面自然也会注意到。2019年1月，国家自然科学基金委发布年度[基金申请指南](http://www.nsfc.gov.cn/nsfc/cen/xmzn/2019xmzn/01/04dq/001.html)，其中在地球科学部分提到：**……特别注重时空大数据的地学解释服务，地球科学既注重理解过去，更关注服务现在和预测未来。**  在计算机科学蓬勃发展的助力之下，地球科学的研究也产生了大量的数据。每个科研院所、高校、公司的服务器上都囤积了大量的存储量论TB算的硬盘。但是，应该与之相匹配的数据解释却仍然是薄弱环节。我们花费海量的时间成本和金钱成本获得的数据，却得不到真正有用和急需的科学结论。跟人一样，吃了很多东西难消化，虽说瘦不了，但是肠胃也很难受。

&nbsp; 明朝文学家张岱说“天下学问，唯夜航船中最难对付。” 一个人在海上，没有信号，身边没有书，也没有参谋，这个时候确实发现卖弄知识是一件很累的事。但是，我认为这个时候显示出来的学问纯属“掉书袋”，一个行走的书柜而已（我承认这段话也是掉书袋）。真正活的知识，并不在对着天涯过客喝大酒时体现出来。让知识永葆活力的唯一办法是让它牢牢嵌入到原有的知识网络中，与其他节点相连、融合、拓展和应用。 一切阅读、学习，最终都要归结到这张网络里面。知识是为实践服务的，博观而约取。从聚焦问题开始，拉扯出一张知识网络去学习、专研、应用，才是"知行合一"。
 
&nbsp; 科学研究是一项长期的、连续的脑力和体力运动，它的根本目标是把知识编织成一张相互关联的网络，在这个过程中加入了各式注脚和同行审议。对于科学来说，独立事实的价值微乎其微，哪怕它在自己的世界中能讲得通，例如伪科学和超科学，就像是没有和已有知识网络相连的孤立节点。至于宗教，它和科学的区别在于后者能承认自己的某些网络节点是错的。如果能通过一个特殊的方法将所有知识有结构地组织起来，那么就会对人类知识的范围和界限有更清晰地视野。在未来几十年里，以人工智能为驱动的计算机会将全部文献编织成一个单一的知识网络，这个网络会培育出新形式的权威。大气科学将是这个比特空间上的知识网络的重要组成部分。

&nbsp; 很难想象还有其他的事物会像人工智能那样拥有摧枯拉朽的力量。在某个现有工作中植入极少量有效的人工智能都会将其效率提高到全新水平。比如把人工智能加入语言中，用它在堆积如山的文本中寻找证据，识别法律案件中的矛盾，或是优化科学论据的使用。在技术发展日新月异的今天，“一万小时成就资深专家定律”基本上会被束之楼阁，工作往往会要求他们在24小时或更短的时间内，迅速了解一个完全陌生的领域，并且拿出专业的解决方案。所有人都会成为菜鸟且永远都能会是菜鸟，这与年龄、经验、职业都没关系。人工智能可以帮助我们这些菜鸟从浩如烟海的信息库中探寻出规律和答案。但是即使人工智能改变了全球经济以及文明，它也会像所有的基础设施一样让人感到极度无聊。把人类从重复性、机械性、记忆性的工作中解放出来，到此人工智能的历史使命就算完成，人类还有额外的艰巨任务：用独有的智慧、丰富的情感以及艺术美感，去解读、创作、表达更好的知识，证明自己存在的价值。

&nbsp; 我觉得能登上“第四次工业革命”的战车是一件非常幸运和荣耀的事情，哪怕要做出一些牺牲。“道阻且长，行则将至”。任何伟大的事业都有一个微不足道的荒谬开头，让我们开始吧。

# 1. 研究背景 

## 1.1 大气模型的符号推理逻辑

> All models are wrong, but some are useful.by George Box

&nbsp; 自文艺复兴后，自然科学和孕育它的人文科学分道扬镳，越来越倾向于形式逻辑，而人文科学越来越倾向于辩证逻辑。大气科学是地球科学的分支，而地球科学又是自然科学与人文科学交叉重叠的领域。大气科学的主干由几百年以来逐步演化推进的数学物理方程和化学反应式构成，然而大气科学的根基却是对自然现象的不断探索，与人类生存息息相关。没有洪涝、暴雨、闪电、台风、沙尘、雾霾、海潮，也就没有对大气的探测过程和物理建模过程，大气科学就会停留在牛顿经典力学的层面。大气科学的迷人之处和恼人之处是相同的，它的复杂性使得“三段论”的形式逻辑无数次被证明失败，也使得“矛盾能统一”的辩证逻辑无数次因盘根错节而体系崩溃。

&nbsp; 科学理论的构建通常使用数学演绎和归纳法。形式逻辑“三段论”的基本组成部分是前提、规则、结论。演绎的目的是求出结论，使用规则和前提来推导出结论，数学家通常使用这种推理。归纳的目的是求出规则，借由大量的前提和结论所组成的实例，来学习规则，自然科学家通常使用这种推理。欧几里德是第一个以三段论形式的演绎法用于构建实际知识体系（几何学）的人。此后，演绎推理成为西方近代科学发展的重要形式，并由此诞生了牛顿力学。麦克斯韦在1865年用演绎法推导出电磁波存在，并预言了光是电磁波，尽管当时没有实验数据证明。然而罗吉尔·培根认为演绎法不能作为科学方法，“思而不学则殆”，而只有归纳法才是真正的科学方法，并且把对实验结果的归纳和数学演绎推理看成是探求知识的两条不同的道路。归纳推理也是历史学家发现统计规律时普遍采用的方法，其局限性是容易困在历史数据中，难以外推至未来。归纳法高度依赖观测数据，由于仪器方法的改进、测量位置和方式等变化，数据本身存在不同程度的误差。

&nbsp; 在大气科学领域，演绎推理的巅峰是大气流体力学方程组，归纳推理的经典案例是南极臭氧层空洞的发现。此外还有溯因推理，溯因目的是求出前提，借由结论和规则，来支援前提以解释结论，医疗诊断和侦探破案通常使用这种推理。《论语》记载“子入太庙，每事问”。无论什么棘手的问题，只需要连续不断地问为什么就能得到真相。同一个结果往往由多种原因引起，因而在应用溯因推理时，常常需要同时推测多种原因。在大气科学中的应用例如推导全球变暖成因。造成上个世纪开始的全球变暖趋势的原因，既有可能是太阳黑子活动异常，或者冰川期循环，或者地球本身周期性公转轨迹变动，也有可能是水汽、二氧化碳、甲烷等温室气体排放量增加所致。尽管如此，这些推理仍然不能很好的解释2000年以后的变暖趋势停顿。

&nbsp; 大气的流动是粘性流体运动。1822年，纳维建立了粘性流体的基本运动方程；1845年，斯托克斯又以更合理的方法导出了这个方程，并称为Navier-Stokes方程(简称N-S方程)。N-S方程和质量守恒和连续方程、地球自转科氏效应、热力学第一定律、理想气体方程构成了大气动力学的理论基础, 但是这组偏微分方程是无法求解的。尽管如此，科学家们的理论推理决对不会停止，逐渐通过演绎推理的方式得到更多的数学公式，也逐渐通过各种仪器的观测结果，经归纳推理加入了更多的经验公式，例如计算饱和水汽压的经验公式，是对无法求解的Clausius–Clapeyron偏微分方程的近似。1971年超级计算机问世后，开始对全部方程组求出相对精确的数值特解<sup>[1]</sup>。

[1] Bauer P, Thorpe A, Brunet G. The quiet revolution of numerical weather prediction[J]. Nature, 2015, 525: 47.

&nbsp; 大气流体方程组求解的思路是把连续流体离散化成一个个的网格。大气模型网格的大小从几公里到几百公里。由于计算机性能的限制，网格不能设置的过小。实际的大气流动往往异常复杂(例如湍流)，理论分析和数值计算会遇到巨大的数学和计算方面的困难。有很多物理过程的发生范围远小于一个网格的大小，这些过程只能用经验性的参数方案来近似，例如云微物理方案<sup>[2]</sup>。即使是它们在数值求解上可能是有效的，并且可以解释，但是过于简化了。例如云雾滴由于颗粒物的内核或者气泡的存在，不满足N-S方程中连续的不可压缩流体假设。所以云雾物理永远是大气科学家挥之不去的梦魇。不仅仅是微尺度，大尺度环流如造成寒潮的冷涡等也难以模拟和预测。

[2] Andreae M O, Rosenfeld D. Aerosol-cloud-precipitation interactions. Part 1. The nature and sources of cloud-active aerosols[J]. Earth-Science Reviews, 2008, 89: 13-41.

&nbsp; 大气的预测性是有限的。即使是用超级计算机，全球天气数值模型GCPMs的预测结果在6天之后准确性开始出现明显下降，17天之后，预测准确率降至为气候平均态，亦即与猜成过去几年的平均值一样的误差<sup>[3]</sup>。即使是一个很小的扰动或者计算误差，也会对全球大气模式带来较大影响。1963年，气象学家洛伦兹提出了在确定性系统中的非周期现象。模式中参数的微小改变将导致完全不一样的结果，使有规律的、周期性的行为，变成完全混乱的状态，称之为“混沌理论”。大气中存在无序的运动，例如布朗运动。这种运动具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中与之前的历史无关。这种最初只在气象中出现的混沌无序现象，后来被发现存在于众多的自然和社会系统中，诸如精神病的发病、心率的节奏、股市的波动等。虽然一个确定的非线性系统可能产生随机结果，但更关键的是发现随机性后面的有序性。

[3] Judt F. Insights into Atmospheric Predictability through Global Convection-Permitting Model Simulations[J], 2018, 75(5): 1477-1497.

&nbsp; 类似于地球科学的形式推理，在20世纪70年代，计算机科学家开始在地质学、医疗等领域打造专家系统，亦即由大量的专家手动编制一系列规则，然后由符号推理形式，根据前提推导出最后结果。这条路后来很快难以为继。因为机器是单纯的接受方，不能主动做改变自己逻辑的事情，所有的事情必须由人类专家一条一条的以规则化的方式去做，非常僵硬（学术界大部分培养人才方式也是如此）。这就是人工智能中的符号学派，它的失败基本上确定了形式逻辑存在外推极限。自然科学的形式主义逻辑推理已经走过漫长岁月，未来发展方向是如何将其运用到计算机的思考模式。因为即使有一天原子世界的逻辑都覆灭了，牛顿力学、相对论、量子力学都不成立了，但是比特空间的逻辑也不会失效，信息熵公式（S=-p*log p）将永存。

> 如果有四件事各有25%的发生几率，我们知道这个时候用00，01，10，11各表示一个事件就可以完全表示出这个随机事件。由信息熵公式可得2bit，也就是说这个事件的信息量是2bit。和自然科学的定律不同，这个定律独立于原子空间而存在。

## 1.2 人工智能的概率统计逻辑

> If you torture the data long enough, it will confess anything. by Ronald Coase

&nbsp; 如果说形式推理就像是在下围棋，精打细算，一步一步的能推导得出下一步的确定结果，那么现实世界就像是德州扑克，存在不确定性，每一件事的发生都有概率。甚至由于人的参与和观测实验，事物的原先状态发生改变，背离了发展轨道，“见相非相”。从统计学角度，所有的现实问题都可转换成概率问题。因此，去寻找现实世界问题的解决方案就等价于寻找一个概率分布。这就是人工智能的概率统计逻辑。

&nbsp; 人工智能的发展并不是一开始就笃定统计逻辑的。在人工智能的早期，符号推理主义比较盛行，通过分析人类智能，然后通过计算机来实现这些功能。符号主义有两个基本假设：（1）信息可以用符号来表示；（2）符号可以通过显式的规则运算（例如IF-THEN）来操作。20 世纪70 年代，研究者认为知识对于人工智能系统非常重要，需要专家来构建知识库。1968年，美国斯坦福大学费根鲍姆研制成功化学专家系统DENDRAL。这是世界上第一个专家系统。1981年，斯坦福大学国际人工智能中心的杜达等人研制成功了地质勘探专家系统PROSPECTOR，为专家系统的实际应用提供了最成功的典范。

&nbsp; 专家系统是使用人类推理规则的计算机模型，用来处理现实世界中需要专家作出解释的复杂问题，并得出与专家相同的结论。专家系统一般采用知识表示和知识推理两种技术，可以看作知识库和推理机的结合。知识库是专家知识在计算机中的映射，推理机是推理逻辑在计算机中的映射。知识库对概念作分析，确认彼此之间的关系，存储了关于事实的描述。推理机将逻辑规则应用到知识库中，推导出新知识。这个过程将迭代，因为知识库中的每个新事实都会触发推理引擎中的新规则。建立专家系统的一般步骤是先设计初始知识库，利用知识表示技术，表达关键概念及其关系。然后编制规则，把知识变换为由编程语言表示的、可供计算机执行的程序。确认规则后，检验知识的合理性、规则的有效性。专家系统已经在各个领域得到了应用并收到良好的效果，但它们解决问题的范围常常受到限制。目前，专家系统缺陷主要表现为：

- 专家系统的功能很大程度上取决于已拥有的知识，但不具备自学习能力，其知识获取主要由知识工程师来完成，这是一件十分困难和费时的事情。
- 大部分的专家系统都是针对某一特定领域建立的，一旦越出这一特定领域，系统就有可能无法有效地运行。
- 缺乏知识的重用性和共享性，与主流信息技术（Web技术、数据库技术）脱节，不具备并行分布和多专家协同功能。并行分布和协作求解是现代信息系统的重要特征。
- 处理不确定问题的能力较差，在归纳推理、模糊推理、不完全推理等方面的能力较差。

&nbsp; 未来专家系统的发展方向是新型的模糊专家系统、神经网络专家系统、分布式专家系统、协同式专家系统和基于Web的专家系统等。在新型专家系统中，除演绎推理之外，还应有归纳推理，各种非标准逻辑推理，以及基于不完全知识和模糊知识的推理等等。同时，新型专家系统适合在多处理器的硬件环境中工作，在总体上提高系统的处理效率。它必须综合若干个领域的子专家系统互相协作解决一个更广泛的问题。随着第三波人工智能高潮发展，网络已成为用户的交互接口，软件也逐步走向网络化。专家系统的发展也顺应该趋势，向人机交互和网络接口服务方向发展。

&nbsp; 尽管专家系统的表现还有可能提升一个层次，但是对于人类的很多智能行为（比如语言理解、图像理解等），我们很难知道其中的原理，也无法描述出这些人类智能背后的“知识”。因此，我们也很难通过知识和推理的方式来打造一个计算机系统。符号主义在这些问题上失败后，研究者开始将研究重点转向让计算机从数据中自己学习。与符号推理主义的发展同时进行的，是连接主义。连接主义是认知科学领域中的一类信息处理的理论。人类的认知过程可以看做是一种信息处理过程，连接主义认为人类的认知过程是由大量简单神经元构成的神经网络中的信息处理过程，而不是符号运算。因此，连接主义模型是由大量的简单的信息处理单元组成的互联网络，具有非线性、分布式、并行化、局部性计算以及自适应性等特性。深度学习的主要模型“神经网络”就是一种连接主义模型。由于神经网络需要大量的数据和计算力，所以20世纪70年代发展起来的神经网络，曾经一度陷入低谷，直到进入21世纪后才成为深度学习的主流框架。

&nbsp; 在符号主义的暮年和连接主义的幼年，是20世纪90年代发展起来的统计学习方法，成为机器学习的主要方法。机器学习的核心思想是让计算机直接地、单纯地从数据中得到特征，并结合专业知识给出结论，本质是基于概率统计。随机性是统计模型的灵魂。虽然在建立模型时，我们希望统计模型能准确地抓住自变量与因变量之间的关系，但是当因变量能够100%被自变量决定时，这时候符号推理才是最好的方法。统计学上的相关性，未必有直接的因果关系，而机器学习的目的寻找那些重复出现的相关模式，因此重复多了就被认为是规律，非常脆弱容易受到数据的欺骗，“三人成虎”、“谎言重复一千遍就被当成了真理”。大气环流的影响有时间的滞后性，例如ENSO的异常与气象的变化，采用统计相关性不会得到理想结果。

&nbsp; 统计模型一般都是基于具体问题设计的参数化模型，特征工程过于依赖人工及相关的专业知识，仍然需要去手工调参，这些工作是一个非常耗时耗力的过程。深度神经网络可以自动提取数据特征，但实际操作中，因为结果可能开始不理想，还是要不断地修改网络结构，这其实就是把机器学习中繁琐的特征工程后置了而已。我们可以将神经网络认为是一种可微分的编程，将符号计算与数值计算在神经网络优化过程中进行了融合。这就意味着深度学习可以被应用于任何可微分的领域，例如大气科学。

&nbsp;符号主义方法的一个优点是可解释性，而这也正是连接主义和统计方法的弊端。深度学习目前最大的挑战是模型的可解释性。深度神经网络可以自动地学到数据丰富的特征，但特征难以解读，“黑箱”进行归纳的逻辑无从掌握，无法解释最后结果的意义。这一点是横亘在很多模型最后产业化的拦路虎。所以在工业界，统计模型中较简单的广义线性模型(generalized linear models)还是占据了半壁江山，这要归功于其良好的解释能力。

&nbsp; 深度学习的另一个问题是很多算法必须用超大规模训练数据集来提升精度，这是对算力的暴力消耗，且容易出现“事倍功半”现象，投入产比低。2017年，“基于雷达图像的短期降水预报”数据科学竞赛吸引了来自全球的1395个团队，其中清华大学的Marmot团队(姚易辰，李中杰)在比赛中脱颖而出，在复赛中以绝对优势排名第一。由于在竞赛中使用了流体力学知识，Marmot团队在未做调参的情况下已经能够大幅领先其他的数据科学队伍。根据流体力学中的泰勒冻结假设，在平稳气流和均匀湍流的条件下，认为大气流场中存在显著的时空关联特性。雷达反射图中的云团在短时间内趋向于在空间以当地平均对流速度平移，短时间内并不会发生外形或者反射强度的剧烈改变。据此，Marmot团队采用传统的关键点提取SIFT方法与卷积神经网络CNN结合，“多快好省”的实现了降水的精准预报，被深圳气象局采纳。这是符号主义和连接主义相结合的成功案例，启发我们要将两种逻辑结合起来，互相取长补短。融合符号主义和连接主义，建立一种简洁、高效并且具有可解释性、能使学术界和工业界同时信服的大气模型，是未来的发展方向。

## 1.3 知识网络的关系推理逻辑

> I saw the best minds of my generation destroyed by statistical models. by Jeff Hammerbacher

&nbsp; 统计方法本身通常无法找到“有意义”的、经得住推理考验的规律，它只能找到重复出现的模式。人类的数学直觉很差，更不擅长统计，数学和概率统计都并不是我们天生的思考方式。和符号推理、统计学不同，人脑神经系统是一个并行的非线性信息处理系统，能将声音、视觉等信号经过多层的编码，从最原始的低层特征不断加工、抽象，最终得到原始信号的语义表示。人是怎么认识这个世界的呢？是不确定性推理和模糊性决策。通过不完整的数据和模糊的事实，推导出结论，这也是侦探破案所需要的智慧。除了不完全的模糊推理之外，人还可以从和外界环境的互动获取智能，根据反馈不断修正自己的行为（例如科研的正反馈普遍较慢），这种模式称之为行为主义，属于人工智能发展的第三个学派。也就是说，**“一叶知秋，管中窥豹”式不完全性推理和“草鞋没样，边打边像”式的反馈行动，是人类智慧的源泉。**

&nbsp; 知识表示与推理 (Knowledge Representation and Reasoning)也是人工智能早期发展而来的传统方法。1958年，John McCarthy认为人工智能系统能做与人脑认知匹敌的常识推断。我们把计算机具备人脑的能力称之为认知计算能力。要想达到认知计算，一个核心的环节就是将人类积累的知识体系表示为计算机能够理解和执行的形式，让计算机能够思考和决策，与此相关的知识表示和推理等环节统称为知识图谱技术。

&nbsp; 人类社会积累的知识体系有着各种各样的形式，而当前机器所能理解执行的知识表示方法无法与之相匹配。例如，在知识图谱学术界广为使用描述语义目标关系的三元组，虽然是目前广为使用，但它简单到甚至无法直接表示“某人某时担任某公司的某职位”这一含有多个要素数量的模式，更不用说它无法直接描述多个目标之间的上下位关系和组成关系等复杂形式。因此，用三元组去对人类积累的知识体系来建模，有着表述能力的欠缺。除此之外，结合具体的文本上下文环境来定义语义目标以及它们之间的关系时，常见的知识手段基本为正则表达式加上布尔逻辑限制，无法描述语义目标出现的频率、顺序、间距等特征。这正是当前的主流自然语言处理技术无法有效做大规模知识抽取的一个关键原因。
 
&nbsp; 图网络（Graph Network），一种基于图结构的广义人工神经网络，它可以直接对真实问题进行建模。图网络可以操作知识的归纳逻辑，看出行为的因果关系，显然对是对深度学习黑箱性的一次突破。如果能让深度学习具备逻辑上的迁移可能，那么具备人类常识的人工智能，将可以在很小的数据样本中完成相对复杂的工作。

&nbsp; 知识图谱就是对客观世界的描述。它描述实体的属性关系，每一个实体可能有若干个属性，实体和实体之间有很多关系，每一个关系基本上可以理解为是一个事实。多元异构知识图谱的构建涉及到在开放的、海量的数据里怎么样去挖掘数据、构建超大规模知识图谱。互联网上海量的多形态数据，蕴含了很多行业应用的有价值信息。从大量无标签非结构化数据中进行开放知识挖掘，抽取了大量的 SPO 三元组。百度飞桨PaddleNLP通过语义空间变换技术实现实体消歧、实体归一等等，解决知识表示形式多样，关联融合困难的问题。百度构建了一个非常庞大的知识图谱，里面含有 6 亿中文实体，事实的量或者说各种关系量已经达到了 3780 亿，比我们人类大脑里面储备的知识多得多。某种程度上，互联网可以被理解为客观世界的一个映射。另外一个映射是在封闭的各行业的领域知识里。ERNIE2.0 通过基于多任务学习的预训练任务迭代，不断提升模型性能。通过对百科、对话，篇章结构、网页搜索、语义关系等超过 13 亿知识不断地学习，不断地积累，ERNIE 在多项中英文自然语言处理任务上取得了业界最好效果，目前已在Github上开源。语言生成，包括机器辅助写作和智能自动创作。创作中可能需要更多辅助的素材，把很多相关的内容呈现出来，这个时候需要做信息的推荐，加入一些领域知识库，一些历史相关的事件脉络，帮助写作。当然还有标题和摘要的生成，这个需要归纳总结，也是很有技术含量的。保证质量包括文本纠错、低质检测、词语润色添加文章标题、自动摘要、文本分类。

&nbsp; 目前的自然语言处理还没有很好地解决常识和推理的问题。新的 NLP 范式是使用大规模文本语料库进行预训练，然后使用特定任务的小数据集进行微调。DNN-NLP 极大地依赖于算力和标记数据，并且也在建模、推理和可解释性方面面临巨大挑战。AI 芯片的新军备竞赛使 AI 研究非常昂贵。

&nbsp; 知识表示（KR）就是易于计算机处理的方式来描述大脑的知识。知识 = 精炼后的数据。好的KR是同时为机器和⼈设计的。例如：ConceptNet (http://conceptnet.io/): json格式, API调用将词语向量化。 RDF： Triple-based Assertion model, Resource Description Framework (资源描述框架)：最简单、最接近自然语言和人脑认知的数据模型。An RDF triple （S,P,O） encodes a statement—a simple logical expression, or claim about the world. RDF是最值得重视的知识图谱表示框架。

&nbsp; 知识图谱工程指的是从不同来源、不同结构的数据中进行知识提取，形成知识存入到知识图谱。文本一般不作为知识图谱构建的初始来源，而多用来做知识图谱补全。KG Embedding/知识图谱嵌⼊ = Entity Vector & Relation Vectors/实体向量和关系向量 =Distributed Representations/知识图谱的分布式表示。关系预测与关系推理是基于知识图谱做挖掘和分析主要任务。

&nbsp;目前主要的空气质量预报方法基于数值模式，如CMAQ、WRF-Chem、CMAx、NAMQM等。数值模式背后有坚实的数学物理方程组做依托，但是计算复杂性过高，迭代求解成本大，同时受限于资料同化，准确的源清单等。《Deep Distributed Fusion Network for Air Quality Prediction》文章模型主要是应用了深度学习，首先对大量不同类别的特征做embedding，然后分别组合输入到不同的子网络再进行融合。子网络是为了捕捉不同影响因子的作用，如气象要素，其他污染物要素，时空要素等。 

&nbsp;《Tackling Climate Change with Machine Learning》指出现在的气候预测大多还是基于气候模式，计算代价巨大。机器学习的引入势必将突破目前数值模式巨大的计算瓶颈。目前机器学习在气候预测上的应用大多还是在模式后处理阶段，用于进行多个气候预测模式结果的融合，而直接融合机器学习算法的气候预测模型目前还没有成熟落地的方案。该领域应用的大多数的ML模型还都是黑箱，对于未来的改进，有待于结合domain knowledge和模型本身提高模型的可解释性。对于ML和AI的应用探索，更需要结合更多的domain knowledge，构建可解释性更强的模型，去更好的服务我们的需求。

&nbsp; 混合模型方法，将物理过程模式与数据驱动型机器学习的通用性耦合起来。现代科学论述包括假设检验、理论发展和计算机建模，这些都是以统计和物理关系，即相关定律为基础的。地球系统数据在激增，信息收集速度远大于人们所能消化的速度。数据的增多并未带对系统预测能力的提高，科学家需要对数据进行理解。 一些时空动态特征比如“记忆效应”可以作为feature手动加入到传统机器学习中，但最新的深度学习已经没有这些限制。但是地学中没有类似被标记的大量训练样本。物理建模（理论驱动）与机器学习建模（数据驱动）过去往往被认为是两个领域，具有不同范式。但其实两种方法可以相互补充的，前者外推能力强，后者更灵活可发现新规律。深度学习将逐渐取代一些半经验的物理模型，未来只会保留最少的基本物理模型，同时指出深度学习在地球科学的应用的最大挑战是理解数据其中的意义。

Reichstein, M., Camps-Valls, G., Stevens, B., Jung, M., Denzler, J., Carvalhais, N., and Prabhat, 2019, Deep  learning and process understanding for data-driven Earth system science: Nature, v. 566, no. 7743, p.  195-204. 

&nbsp; 预测气候的困难主要来自于气候的响应是非线性的。将全球气候模式预报的结果赋予统计学的意义，检测潜在的关联，在经典假设检验的基础上决定是对是错，是存是留(41741 个关系)。

Caldwell, P. M., Bretherton, C. S., Zelinka, M. D., Klein, S. A., Santer, B. D., and Sanderson, B. M., 2014, Statistical  significance of climate sensitivity predictors obtained by data mining, v. 41, no. 5, p. 1803-1808.

&nbsp; 数值模式代表了几百年以来自然科学积累和技术进步的产物，但是细数起来并很少有根本的物理规律上的突破。云雾降水、边界层过程等次网格过程的理解不全面，才需要参数化。1950年，Thompson等人首次量化初始误差对于后续预测结果的影响， 劳伦兹在量化大气系统的可预测性过程中提出了混沌理论。它的主要结论是不稳定系统具有确定的、静止的可预测性，导致了模型不确定性的量化成为模型的必需。混沌系统的非线性变化意味着纯统计模型是无法量化预测的不确定性的。物理模型本身的固有缺陷需要一个完全不同的方法来解决。

Bauer, P., Thorpe, A., and Brunet, G., 2015, The quiet revolution of numerical weather prediction: Nature, v.  525, p. 47.

&nbsp; 贝叶斯方法是一个非参数化的统计概率方法，利用它可以实现自动化分析数据，结果可解释，无论数据是大是小。数据越大，预测能力越高。它将变革机器学习和科学模型。许多大数据就是小数据的集合。

Ghahramani, Z., 2015, Probabilistic machine learning and artificial intelligence: Nature, v. 521, p. 452.

&nbsp; 非监督学习一直以来被监督学习的成功光芒所掩盖。然而，长期来看，非监督学习更加重要。人类和动物的学习方式是非监督性的。深度学习方法属于表示学习，人工智能的最终发展趋势是将表示学习和复杂推理结合在一起。新的方法需要取代基于特定规则的符号表示，例如向量化和分布式表示。

LeCun, Y., Bengio, Y., and Hinton, G., 2015, Deep learning: Nature, v. 521, p. 436.

&nbsp; 深度学习是可以应用到自然界复杂的物理过程中的。背景先验知识可以用来设计深度学习框架。数值模式和深度学习二者可以互补。

de Bezenac, E., Pajot, A. & Gallinari, 2017, Deep learning for physical processes: incorporating prior scientifc  knowledge.

&nbsp; 综上所述，人工智能的未来是“知识表示与推理”、“不确定性处理”、“人机交互”。了解实际应用场景，牢记以结果为导向的解决问题的思维方式，将现有的语言和领域知识整合到模型中，使人和机器相得益彰，实现人工智能和人类智能的双向结合，这才是“盛德大业”——让所有人都能得益才能长久。

# 2. 方法论

## 2.1 知识网络、统计学习、物理模型融合

&nbsp; 和机器学习解决问题的思路一样，**本研究计划也属于工程问题**。工程问题进展的关键，是考虑约束条件下清晰地定义了目标函数和损失函数 (Loss Function)。所以只要做两件事：一是把目标定量化，二是建立起评测系统，此后不管工程的进展快慢，都能慢慢进化到最优。

根据《大气科学词典》，共计25808个概念（中英双语）。

根据《Statistical significance of climate sensitivity predictors obtained by data mining》中对气候模型的结果统计学检验，共计41741个有效关系。

albert_zh：海量中文语料上预训练ALBERT模型。《ALBERT: A Lite BERT For Self-Supervised Learning Of Language Representations》。https://github.com/Limin-Feng1993/albert_zh.

PaddleNLP：百度飞桨自然语言处理模型库 https://github.com/Limin-Feng1993/models.

中文预训练RoBERTa模型 https://github.com/Limin-Feng1993/roberta_zh. BERT的改进版，通过改进训练任务和数据生成方式、训练更久、使用更大批次、使用更多数据等获得了State of The Art的效果；可以用Bert直接加载。用TensorFlow实现了在大规模中文上RoBERTa的预训练，也会提供PyTorch的预训练模型和加载方式。

谷歌BERT以及Pytorch英文预训练模型：PyTorch Pretrained BERT:https://github.com/Limin-Feng1993/pytorch-pretrained-BERT. BERT: https://github.com/Limin-Feng1993/bert. 

Longman Communication 3000: https://github.com/Limin-Feng1993/Longman-Communication-3000.


## 2.2 目标函数

- 动机“善”：让天下没有难写的文章。
- 解释“真”：基于经典知识网络建构，不断验真。
- 展现“美”：数据可视化与绘图制片大众传播。
- 合乎“道”：前瞻领域+技术门槛高+市场一片蓝海。

## 2.3 损失函数

## 2.4 应用场景

&nbsp; 并行计算资源成本的削减。

1.数据分析得出定量结论—机器学习流水线
2.知识网络链接赋予意义—拓扑图谱流水线
3.总结概括主旨表达清晰—自然语言流水线

# 3. 尾声

&nbsp; 生命之树常青，而理论是灰色的。人们每天看到的、遇到的只是一个表象，怎样从自然和社会的表象中发现其内在的规律，通过对这些表象的整理和分析就会得出一些更本质的东西，再经过人的思维取舍抽象，这就是科学和思想。研究是看别人看到的，想别人想不到的。历史和数据都是一样的，不一样的是怎样取舍、整合、解读、用一根什么样的线把它们穿起来。学术上的独创有时候仅仅是总结出一个概念而已。

**谁终将声震人间，必长久深自缄默；谁终将点燃闪电，必长久如云漂泊。**


